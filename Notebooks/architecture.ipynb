{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torchsummary\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import Linear, Sequential, Dropout, ReLU\n",
    "from torch import load, inference_mode, round, sigmoid, randn\n",
    "from sklearn.metrics import accuracy_score, multilabel_confusion_matrix, classification_report\n",
    "from torchvision.models.regnet import regnet_y_3_2gf, RegNet_Y_3_2GF_Weights\n",
    "from torchvision.models.swin_transformer import swin_v2_t, Swin_V2_T_Weights\n",
    "from torchvision.models.efficientnet import efficientnet_v2_s, EfficientNet_V2_S_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regnet_model = regnet_y_3_2gf()\n",
    "regnet_model.fc = Linear(1512, 28)\n",
    "regnet_model.load_state_dict(load(\"../Models/FinetunedRegNet.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_model = efficientnet_v2_s()\n",
    "efficientnet_model.classifier = Sequential(\n",
    "    Dropout(p=0.2),\n",
    "    ReLU(),\n",
    "    Linear(in_features=1280, out_features=28)\n",
    ")\n",
    "efficientnet_model.load_state_dict(load(\"../Models/FinetunedEfficientNet.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swinv2_model = swin_v2_t()\n",
    "swinv2_model.head = Linear(768, 28)\n",
    "swinv2_model.load_state_dict(load(\"../Models/FinetunedSwinV2.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 112, 112]             864\n",
      "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
      "              ReLU-3         [-1, 32, 112, 112]               0\n",
      "            Conv2d-4           [-1, 72, 56, 56]           2,304\n",
      "       BatchNorm2d-5           [-1, 72, 56, 56]             144\n",
      "            Conv2d-6         [-1, 72, 112, 112]           2,304\n",
      "       BatchNorm2d-7         [-1, 72, 112, 112]             144\n",
      "              ReLU-8         [-1, 72, 112, 112]               0\n",
      "            Conv2d-9           [-1, 72, 56, 56]          15,552\n",
      "      BatchNorm2d-10           [-1, 72, 56, 56]             144\n",
      "             ReLU-11           [-1, 72, 56, 56]               0\n",
      "AdaptiveAvgPool2d-12             [-1, 72, 1, 1]               0\n",
      "           Conv2d-13              [-1, 8, 1, 1]             584\n",
      "             ReLU-14              [-1, 8, 1, 1]               0\n",
      "           Conv2d-15             [-1, 72, 1, 1]             648\n",
      "          Sigmoid-16             [-1, 72, 1, 1]               0\n",
      "SqueezeExcitation-17           [-1, 72, 56, 56]               0\n",
      "           Conv2d-18           [-1, 72, 56, 56]           5,184\n",
      "      BatchNorm2d-19           [-1, 72, 56, 56]             144\n",
      "             ReLU-20           [-1, 72, 56, 56]               0\n",
      "ResBottleneckBlock-21           [-1, 72, 56, 56]               0\n",
      "           Conv2d-22           [-1, 72, 56, 56]           5,184\n",
      "      BatchNorm2d-23           [-1, 72, 56, 56]             144\n",
      "             ReLU-24           [-1, 72, 56, 56]               0\n",
      "           Conv2d-25           [-1, 72, 56, 56]          15,552\n",
      "      BatchNorm2d-26           [-1, 72, 56, 56]             144\n",
      "             ReLU-27           [-1, 72, 56, 56]               0\n",
      "AdaptiveAvgPool2d-28             [-1, 72, 1, 1]               0\n",
      "           Conv2d-29             [-1, 18, 1, 1]           1,314\n",
      "             ReLU-30             [-1, 18, 1, 1]               0\n",
      "           Conv2d-31             [-1, 72, 1, 1]           1,368\n",
      "          Sigmoid-32             [-1, 72, 1, 1]               0\n",
      "SqueezeExcitation-33           [-1, 72, 56, 56]               0\n",
      "           Conv2d-34           [-1, 72, 56, 56]           5,184\n",
      "      BatchNorm2d-35           [-1, 72, 56, 56]             144\n",
      "             ReLU-36           [-1, 72, 56, 56]               0\n",
      "ResBottleneckBlock-37           [-1, 72, 56, 56]               0\n",
      "           Conv2d-38          [-1, 216, 28, 28]          15,552\n",
      "      BatchNorm2d-39          [-1, 216, 28, 28]             432\n",
      "           Conv2d-40          [-1, 216, 56, 56]          15,552\n",
      "      BatchNorm2d-41          [-1, 216, 56, 56]             432\n",
      "             ReLU-42          [-1, 216, 56, 56]               0\n",
      "           Conv2d-43          [-1, 216, 28, 28]          46,656\n",
      "      BatchNorm2d-44          [-1, 216, 28, 28]             432\n",
      "             ReLU-45          [-1, 216, 28, 28]               0\n",
      "AdaptiveAvgPool2d-46            [-1, 216, 1, 1]               0\n",
      "           Conv2d-47             [-1, 18, 1, 1]           3,906\n",
      "             ReLU-48             [-1, 18, 1, 1]               0\n",
      "           Conv2d-49            [-1, 216, 1, 1]           4,104\n",
      "          Sigmoid-50            [-1, 216, 1, 1]               0\n",
      "SqueezeExcitation-51          [-1, 216, 28, 28]               0\n",
      "           Conv2d-52          [-1, 216, 28, 28]          46,656\n",
      "      BatchNorm2d-53          [-1, 216, 28, 28]             432\n",
      "             ReLU-54          [-1, 216, 28, 28]               0\n",
      "ResBottleneckBlock-55          [-1, 216, 28, 28]               0\n",
      "           Conv2d-56          [-1, 216, 28, 28]          46,656\n",
      "      BatchNorm2d-57          [-1, 216, 28, 28]             432\n",
      "             ReLU-58          [-1, 216, 28, 28]               0\n",
      "           Conv2d-59          [-1, 216, 28, 28]          46,656\n",
      "      BatchNorm2d-60          [-1, 216, 28, 28]             432\n",
      "             ReLU-61          [-1, 216, 28, 28]               0\n",
      "AdaptiveAvgPool2d-62            [-1, 216, 1, 1]               0\n",
      "           Conv2d-63             [-1, 54, 1, 1]          11,718\n",
      "             ReLU-64             [-1, 54, 1, 1]               0\n",
      "           Conv2d-65            [-1, 216, 1, 1]          11,880\n",
      "          Sigmoid-66            [-1, 216, 1, 1]               0\n",
      "SqueezeExcitation-67          [-1, 216, 28, 28]               0\n",
      "           Conv2d-68          [-1, 216, 28, 28]          46,656\n",
      "      BatchNorm2d-69          [-1, 216, 28, 28]             432\n",
      "             ReLU-70          [-1, 216, 28, 28]               0\n",
      "ResBottleneckBlock-71          [-1, 216, 28, 28]               0\n",
      "           Conv2d-72          [-1, 216, 28, 28]          46,656\n",
      "      BatchNorm2d-73          [-1, 216, 28, 28]             432\n",
      "             ReLU-74          [-1, 216, 28, 28]               0\n",
      "           Conv2d-75          [-1, 216, 28, 28]          46,656\n",
      "      BatchNorm2d-76          [-1, 216, 28, 28]             432\n",
      "             ReLU-77          [-1, 216, 28, 28]               0\n",
      "AdaptiveAvgPool2d-78            [-1, 216, 1, 1]               0\n",
      "           Conv2d-79             [-1, 54, 1, 1]          11,718\n",
      "             ReLU-80             [-1, 54, 1, 1]               0\n",
      "           Conv2d-81            [-1, 216, 1, 1]          11,880\n",
      "          Sigmoid-82            [-1, 216, 1, 1]               0\n",
      "SqueezeExcitation-83          [-1, 216, 28, 28]               0\n",
      "           Conv2d-84          [-1, 216, 28, 28]          46,656\n",
      "      BatchNorm2d-85          [-1, 216, 28, 28]             432\n",
      "             ReLU-86          [-1, 216, 28, 28]               0\n",
      "ResBottleneckBlock-87          [-1, 216, 28, 28]               0\n",
      "           Conv2d-88          [-1, 216, 28, 28]          46,656\n",
      "      BatchNorm2d-89          [-1, 216, 28, 28]             432\n",
      "             ReLU-90          [-1, 216, 28, 28]               0\n",
      "           Conv2d-91          [-1, 216, 28, 28]          46,656\n",
      "      BatchNorm2d-92          [-1, 216, 28, 28]             432\n",
      "             ReLU-93          [-1, 216, 28, 28]               0\n",
      "AdaptiveAvgPool2d-94            [-1, 216, 1, 1]               0\n",
      "           Conv2d-95             [-1, 54, 1, 1]          11,718\n",
      "             ReLU-96             [-1, 54, 1, 1]               0\n",
      "           Conv2d-97            [-1, 216, 1, 1]          11,880\n",
      "          Sigmoid-98            [-1, 216, 1, 1]               0\n",
      "SqueezeExcitation-99          [-1, 216, 28, 28]               0\n",
      "          Conv2d-100          [-1, 216, 28, 28]          46,656\n",
      "     BatchNorm2d-101          [-1, 216, 28, 28]             432\n",
      "            ReLU-102          [-1, 216, 28, 28]               0\n",
      "ResBottleneckBlock-103          [-1, 216, 28, 28]               0\n",
      "          Conv2d-104          [-1, 216, 28, 28]          46,656\n",
      "     BatchNorm2d-105          [-1, 216, 28, 28]             432\n",
      "            ReLU-106          [-1, 216, 28, 28]               0\n",
      "          Conv2d-107          [-1, 216, 28, 28]          46,656\n",
      "     BatchNorm2d-108          [-1, 216, 28, 28]             432\n",
      "            ReLU-109          [-1, 216, 28, 28]               0\n",
      "AdaptiveAvgPool2d-110            [-1, 216, 1, 1]               0\n",
      "          Conv2d-111             [-1, 54, 1, 1]          11,718\n",
      "            ReLU-112             [-1, 54, 1, 1]               0\n",
      "          Conv2d-113            [-1, 216, 1, 1]          11,880\n",
      "         Sigmoid-114            [-1, 216, 1, 1]               0\n",
      "SqueezeExcitation-115          [-1, 216, 28, 28]               0\n",
      "          Conv2d-116          [-1, 216, 28, 28]          46,656\n",
      "     BatchNorm2d-117          [-1, 216, 28, 28]             432\n",
      "            ReLU-118          [-1, 216, 28, 28]               0\n",
      "ResBottleneckBlock-119          [-1, 216, 28, 28]               0\n",
      "          Conv2d-120          [-1, 576, 14, 14]         124,416\n",
      "     BatchNorm2d-121          [-1, 576, 14, 14]           1,152\n",
      "          Conv2d-122          [-1, 576, 28, 28]         124,416\n",
      "     BatchNorm2d-123          [-1, 576, 28, 28]           1,152\n",
      "            ReLU-124          [-1, 576, 28, 28]               0\n",
      "          Conv2d-125          [-1, 576, 14, 14]         124,416\n",
      "     BatchNorm2d-126          [-1, 576, 14, 14]           1,152\n",
      "            ReLU-127          [-1, 576, 14, 14]               0\n",
      "AdaptiveAvgPool2d-128            [-1, 576, 1, 1]               0\n",
      "          Conv2d-129             [-1, 54, 1, 1]          31,158\n",
      "            ReLU-130             [-1, 54, 1, 1]               0\n",
      "          Conv2d-131            [-1, 576, 1, 1]          31,680\n",
      "         Sigmoid-132            [-1, 576, 1, 1]               0\n",
      "SqueezeExcitation-133          [-1, 576, 14, 14]               0\n",
      "          Conv2d-134          [-1, 576, 14, 14]         331,776\n",
      "     BatchNorm2d-135          [-1, 576, 14, 14]           1,152\n",
      "            ReLU-136          [-1, 576, 14, 14]               0\n",
      "ResBottleneckBlock-137          [-1, 576, 14, 14]               0\n",
      "          Conv2d-138          [-1, 576, 14, 14]         331,776\n",
      "     BatchNorm2d-139          [-1, 576, 14, 14]           1,152\n",
      "            ReLU-140          [-1, 576, 14, 14]               0\n",
      "          Conv2d-141          [-1, 576, 14, 14]         124,416\n",
      "     BatchNorm2d-142          [-1, 576, 14, 14]           1,152\n",
      "            ReLU-143          [-1, 576, 14, 14]               0\n",
      "AdaptiveAvgPool2d-144            [-1, 576, 1, 1]               0\n",
      "          Conv2d-145            [-1, 144, 1, 1]          83,088\n",
      "            ReLU-146            [-1, 144, 1, 1]               0\n",
      "          Conv2d-147            [-1, 576, 1, 1]          83,520\n",
      "         Sigmoid-148            [-1, 576, 1, 1]               0\n",
      "SqueezeExcitation-149          [-1, 576, 14, 14]               0\n",
      "          Conv2d-150          [-1, 576, 14, 14]         331,776\n",
      "     BatchNorm2d-151          [-1, 576, 14, 14]           1,152\n",
      "            ReLU-152          [-1, 576, 14, 14]               0\n",
      "ResBottleneckBlock-153          [-1, 576, 14, 14]               0\n",
      "          Conv2d-154          [-1, 576, 14, 14]         331,776\n",
      "     BatchNorm2d-155          [-1, 576, 14, 14]           1,152\n",
      "            ReLU-156          [-1, 576, 14, 14]               0\n",
      "          Conv2d-157          [-1, 576, 14, 14]         124,416\n",
      "     BatchNorm2d-158          [-1, 576, 14, 14]           1,152\n",
      "            ReLU-159          [-1, 576, 14, 14]               0\n",
      "AdaptiveAvgPool2d-160            [-1, 576, 1, 1]               0\n",
      "          Conv2d-161            [-1, 144, 1, 1]          83,088\n",
      "            ReLU-162            [-1, 144, 1, 1]               0\n",
      "          Conv2d-163            [-1, 576, 1, 1]          83,520\n",
      "         Sigmoid-164            [-1, 576, 1, 1]               0\n",
      "SqueezeExcitation-165          [-1, 576, 14, 14]               0\n",
      "          Conv2d-166          [-1, 576, 14, 14]         331,776\n",
      "     BatchNorm2d-167          [-1, 576, 14, 14]           1,152\n",
      "            ReLU-168          [-1, 576, 14, 14]               0\n",
      "ResBottleneckBlock-169          [-1, 576, 14, 14]               0\n",
      "          Conv2d-170          [-1, 576, 14, 14]         331,776\n",
      "     BatchNorm2d-171          [-1, 576, 14, 14]           1,152\n",
      "            ReLU-172          [-1, 576, 14, 14]               0\n",
      "          Conv2d-173          [-1, 576, 14, 14]         124,416\n",
      "     BatchNorm2d-174          [-1, 576, 14, 14]           1,152\n",
      "            ReLU-175          [-1, 576, 14, 14]               0\n",
      "AdaptiveAvgPool2d-176            [-1, 576, 1, 1]               0\n",
      "          Conv2d-177            [-1, 144, 1, 1]          83,088\n",
      "            ReLU-178            [-1, 144, 1, 1]               0\n",
      "          Conv2d-179            [-1, 576, 1, 1]          83,520\n",
      "         Sigmoid-180            [-1, 576, 1, 1]               0\n",
      "SqueezeExcitation-181          [-1, 576, 14, 14]               0\n",
      "          Conv2d-182          [-1, 576, 14, 14]         331,776\n",
      "     BatchNorm2d-183          [-1, 576, 14, 14]           1,152\n",
      "            ReLU-184          [-1, 576, 14, 14]               0\n",
      "ResBottleneckBlock-185          [-1, 576, 14, 14]               0\n",
      "          Conv2d-186          [-1, 576, 14, 14]         331,776\n",
      "     BatchNorm2d-187          [-1, 576, 14, 14]           1,152\n",
      "            ReLU-188          [-1, 576, 14, 14]               0\n",
      "          Conv2d-189          [-1, 576, 14, 14]         124,416\n",
      "     BatchNorm2d-190          [-1, 576, 14, 14]           1,152\n",
      "            ReLU-191          [-1, 576, 14, 14]               0\n",
      "AdaptiveAvgPool2d-192            [-1, 576, 1, 1]               0\n",
      "          Conv2d-193            [-1, 144, 1, 1]          83,088\n",
      "            ReLU-194            [-1, 144, 1, 1]               0\n",
      "          Conv2d-195            [-1, 576, 1, 1]          83,520\n",
      "         Sigmoid-196            [-1, 576, 1, 1]               0\n",
      "SqueezeExcitation-197          [-1, 576, 14, 14]               0\n",
      "          Conv2d-198          [-1, 576, 14, 14]         331,776\n",
      "     BatchNorm2d-199          [-1, 576, 14, 14]           1,152\n",
      "            ReLU-200          [-1, 576, 14, 14]               0\n",
      "ResBottleneckBlock-201          [-1, 576, 14, 14]               0\n",
      "          Conv2d-202          [-1, 576, 14, 14]         331,776\n",
      "     BatchNorm2d-203          [-1, 576, 14, 14]           1,152\n",
      "            ReLU-204          [-1, 576, 14, 14]               0\n",
      "          Conv2d-205          [-1, 576, 14, 14]         124,416\n",
      "     BatchNorm2d-206          [-1, 576, 14, 14]           1,152\n",
      "            ReLU-207          [-1, 576, 14, 14]               0\n",
      "AdaptiveAvgPool2d-208            [-1, 576, 1, 1]               0\n",
      "          Conv2d-209            [-1, 144, 1, 1]          83,088\n",
      "            ReLU-210            [-1, 144, 1, 1]               0\n",
      "          Conv2d-211            [-1, 576, 1, 1]          83,520\n",
      "         Sigmoid-212            [-1, 576, 1, 1]               0\n",
      "SqueezeExcitation-213          [-1, 576, 14, 14]               0\n",
      "          Conv2d-214          [-1, 576, 14, 14]         331,776\n",
      "     BatchNorm2d-215          [-1, 576, 14, 14]           1,152\n",
      "            ReLU-216          [-1, 576, 14, 14]               0\n",
      "ResBottleneckBlock-217          [-1, 576, 14, 14]               0\n",
      "          Conv2d-218          [-1, 576, 14, 14]         331,776\n",
      "     BatchNorm2d-219          [-1, 576, 14, 14]           1,152\n",
      "            ReLU-220          [-1, 576, 14, 14]               0\n",
      "          Conv2d-221          [-1, 576, 14, 14]         124,416\n",
      "     BatchNorm2d-222          [-1, 576, 14, 14]           1,152\n",
      "            ReLU-223          [-1, 576, 14, 14]               0\n",
      "AdaptiveAvgPool2d-224            [-1, 576, 1, 1]               0\n",
      "          Conv2d-225            [-1, 144, 1, 1]          83,088\n",
      "            ReLU-226            [-1, 144, 1, 1]               0\n",
      "          Conv2d-227            [-1, 576, 1, 1]          83,520\n",
      "         Sigmoid-228            [-1, 576, 1, 1]               0\n",
      "SqueezeExcitation-229          [-1, 576, 14, 14]               0\n",
      "          Conv2d-230          [-1, 576, 14, 14]         331,776\n",
      "     BatchNorm2d-231          [-1, 576, 14, 14]           1,152\n",
      "            ReLU-232          [-1, 576, 14, 14]               0\n",
      "ResBottleneckBlock-233          [-1, 576, 14, 14]               0\n",
      "          Conv2d-234          [-1, 576, 14, 14]         331,776\n",
      "     BatchNorm2d-235          [-1, 576, 14, 14]           1,152\n",
      "            ReLU-236          [-1, 576, 14, 14]               0\n",
      "          Conv2d-237          [-1, 576, 14, 14]         124,416\n",
      "     BatchNorm2d-238          [-1, 576, 14, 14]           1,152\n",
      "            ReLU-239          [-1, 576, 14, 14]               0\n",
      "AdaptiveAvgPool2d-240            [-1, 576, 1, 1]               0\n",
      "          Conv2d-241            [-1, 144, 1, 1]          83,088\n",
      "            ReLU-242            [-1, 144, 1, 1]               0\n",
      "          Conv2d-243            [-1, 576, 1, 1]          83,520\n",
      "         Sigmoid-244            [-1, 576, 1, 1]               0\n",
      "SqueezeExcitation-245          [-1, 576, 14, 14]               0\n",
      "          Conv2d-246          [-1, 576, 14, 14]         331,776\n",
      "     BatchNorm2d-247          [-1, 576, 14, 14]           1,152\n",
      "            ReLU-248          [-1, 576, 14, 14]               0\n",
      "ResBottleneckBlock-249          [-1, 576, 14, 14]               0\n",
      "          Conv2d-250          [-1, 576, 14, 14]         331,776\n",
      "     BatchNorm2d-251          [-1, 576, 14, 14]           1,152\n",
      "            ReLU-252          [-1, 576, 14, 14]               0\n",
      "          Conv2d-253          [-1, 576, 14, 14]         124,416\n",
      "     BatchNorm2d-254          [-1, 576, 14, 14]           1,152\n",
      "            ReLU-255          [-1, 576, 14, 14]               0\n",
      "AdaptiveAvgPool2d-256            [-1, 576, 1, 1]               0\n",
      "          Conv2d-257            [-1, 144, 1, 1]          83,088\n",
      "            ReLU-258            [-1, 144, 1, 1]               0\n",
      "          Conv2d-259            [-1, 576, 1, 1]          83,520\n",
      "         Sigmoid-260            [-1, 576, 1, 1]               0\n",
      "SqueezeExcitation-261          [-1, 576, 14, 14]               0\n",
      "          Conv2d-262          [-1, 576, 14, 14]         331,776\n",
      "     BatchNorm2d-263          [-1, 576, 14, 14]           1,152\n",
      "            ReLU-264          [-1, 576, 14, 14]               0\n",
      "ResBottleneckBlock-265          [-1, 576, 14, 14]               0\n",
      "          Conv2d-266          [-1, 576, 14, 14]         331,776\n",
      "     BatchNorm2d-267          [-1, 576, 14, 14]           1,152\n",
      "            ReLU-268          [-1, 576, 14, 14]               0\n",
      "          Conv2d-269          [-1, 576, 14, 14]         124,416\n",
      "     BatchNorm2d-270          [-1, 576, 14, 14]           1,152\n",
      "            ReLU-271          [-1, 576, 14, 14]               0\n",
      "AdaptiveAvgPool2d-272            [-1, 576, 1, 1]               0\n",
      "          Conv2d-273            [-1, 144, 1, 1]          83,088\n",
      "            ReLU-274            [-1, 144, 1, 1]               0\n",
      "          Conv2d-275            [-1, 576, 1, 1]          83,520\n",
      "         Sigmoid-276            [-1, 576, 1, 1]               0\n",
      "SqueezeExcitation-277          [-1, 576, 14, 14]               0\n",
      "          Conv2d-278          [-1, 576, 14, 14]         331,776\n",
      "     BatchNorm2d-279          [-1, 576, 14, 14]           1,152\n",
      "            ReLU-280          [-1, 576, 14, 14]               0\n",
      "ResBottleneckBlock-281          [-1, 576, 14, 14]               0\n",
      "          Conv2d-282          [-1, 576, 14, 14]         331,776\n",
      "     BatchNorm2d-283          [-1, 576, 14, 14]           1,152\n",
      "            ReLU-284          [-1, 576, 14, 14]               0\n",
      "          Conv2d-285          [-1, 576, 14, 14]         124,416\n",
      "     BatchNorm2d-286          [-1, 576, 14, 14]           1,152\n",
      "            ReLU-287          [-1, 576, 14, 14]               0\n",
      "AdaptiveAvgPool2d-288            [-1, 576, 1, 1]               0\n",
      "          Conv2d-289            [-1, 144, 1, 1]          83,088\n",
      "            ReLU-290            [-1, 144, 1, 1]               0\n",
      "          Conv2d-291            [-1, 576, 1, 1]          83,520\n",
      "         Sigmoid-292            [-1, 576, 1, 1]               0\n",
      "SqueezeExcitation-293          [-1, 576, 14, 14]               0\n",
      "          Conv2d-294          [-1, 576, 14, 14]         331,776\n",
      "     BatchNorm2d-295          [-1, 576, 14, 14]           1,152\n",
      "            ReLU-296          [-1, 576, 14, 14]               0\n",
      "ResBottleneckBlock-297          [-1, 576, 14, 14]               0\n",
      "          Conv2d-298          [-1, 576, 14, 14]         331,776\n",
      "     BatchNorm2d-299          [-1, 576, 14, 14]           1,152\n",
      "            ReLU-300          [-1, 576, 14, 14]               0\n",
      "          Conv2d-301          [-1, 576, 14, 14]         124,416\n",
      "     BatchNorm2d-302          [-1, 576, 14, 14]           1,152\n",
      "            ReLU-303          [-1, 576, 14, 14]               0\n",
      "AdaptiveAvgPool2d-304            [-1, 576, 1, 1]               0\n",
      "          Conv2d-305            [-1, 144, 1, 1]          83,088\n",
      "            ReLU-306            [-1, 144, 1, 1]               0\n",
      "          Conv2d-307            [-1, 576, 1, 1]          83,520\n",
      "         Sigmoid-308            [-1, 576, 1, 1]               0\n",
      "SqueezeExcitation-309          [-1, 576, 14, 14]               0\n",
      "          Conv2d-310          [-1, 576, 14, 14]         331,776\n",
      "     BatchNorm2d-311          [-1, 576, 14, 14]           1,152\n",
      "            ReLU-312          [-1, 576, 14, 14]               0\n",
      "ResBottleneckBlock-313          [-1, 576, 14, 14]               0\n",
      "          Conv2d-314          [-1, 576, 14, 14]         331,776\n",
      "     BatchNorm2d-315          [-1, 576, 14, 14]           1,152\n",
      "            ReLU-316          [-1, 576, 14, 14]               0\n",
      "          Conv2d-317          [-1, 576, 14, 14]         124,416\n",
      "     BatchNorm2d-318          [-1, 576, 14, 14]           1,152\n",
      "            ReLU-319          [-1, 576, 14, 14]               0\n",
      "AdaptiveAvgPool2d-320            [-1, 576, 1, 1]               0\n",
      "          Conv2d-321            [-1, 144, 1, 1]          83,088\n",
      "            ReLU-322            [-1, 144, 1, 1]               0\n",
      "          Conv2d-323            [-1, 576, 1, 1]          83,520\n",
      "         Sigmoid-324            [-1, 576, 1, 1]               0\n",
      "SqueezeExcitation-325          [-1, 576, 14, 14]               0\n",
      "          Conv2d-326          [-1, 576, 14, 14]         331,776\n",
      "     BatchNorm2d-327          [-1, 576, 14, 14]           1,152\n",
      "            ReLU-328          [-1, 576, 14, 14]               0\n",
      "ResBottleneckBlock-329          [-1, 576, 14, 14]               0\n",
      "          Conv2d-330           [-1, 1512, 7, 7]         870,912\n",
      "     BatchNorm2d-331           [-1, 1512, 7, 7]           3,024\n",
      "          Conv2d-332         [-1, 1512, 14, 14]         870,912\n",
      "     BatchNorm2d-333         [-1, 1512, 14, 14]           3,024\n",
      "            ReLU-334         [-1, 1512, 14, 14]               0\n",
      "          Conv2d-335           [-1, 1512, 7, 7]         326,592\n",
      "     BatchNorm2d-336           [-1, 1512, 7, 7]           3,024\n",
      "            ReLU-337           [-1, 1512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-338           [-1, 1512, 1, 1]               0\n",
      "          Conv2d-339            [-1, 144, 1, 1]         217,872\n",
      "            ReLU-340            [-1, 144, 1, 1]               0\n",
      "          Conv2d-341           [-1, 1512, 1, 1]         219,240\n",
      "         Sigmoid-342           [-1, 1512, 1, 1]               0\n",
      "SqueezeExcitation-343           [-1, 1512, 7, 7]               0\n",
      "          Conv2d-344           [-1, 1512, 7, 7]       2,286,144\n",
      "     BatchNorm2d-345           [-1, 1512, 7, 7]           3,024\n",
      "            ReLU-346           [-1, 1512, 7, 7]               0\n",
      "ResBottleneckBlock-347           [-1, 1512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-348           [-1, 1512, 1, 1]               0\n",
      "          Linear-349                   [-1, 28]          42,364\n",
      "================================================================\n",
      "Total params: 17,965,702\n",
      "Trainable params: 17,965,702\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 296.67\n",
      "Params size (MB): 68.53\n",
      "Estimated Total Size (MB): 365.77\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(regnet_model.to('cuda'),(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 24, 192, 192]             648\n",
      "       BatchNorm2d-2         [-1, 24, 192, 192]              48\n",
      "              SiLU-3         [-1, 24, 192, 192]               0\n",
      "            Conv2d-4         [-1, 24, 192, 192]           5,184\n",
      "       BatchNorm2d-5         [-1, 24, 192, 192]              48\n",
      "              SiLU-6         [-1, 24, 192, 192]               0\n",
      "   StochasticDepth-7         [-1, 24, 192, 192]               0\n",
      "       FusedMBConv-8         [-1, 24, 192, 192]               0\n",
      "            Conv2d-9         [-1, 24, 192, 192]           5,184\n",
      "      BatchNorm2d-10         [-1, 24, 192, 192]              48\n",
      "             SiLU-11         [-1, 24, 192, 192]               0\n",
      "  StochasticDepth-12         [-1, 24, 192, 192]               0\n",
      "      FusedMBConv-13         [-1, 24, 192, 192]               0\n",
      "           Conv2d-14           [-1, 96, 96, 96]          20,736\n",
      "      BatchNorm2d-15           [-1, 96, 96, 96]             192\n",
      "             SiLU-16           [-1, 96, 96, 96]               0\n",
      "           Conv2d-17           [-1, 48, 96, 96]           4,608\n",
      "      BatchNorm2d-18           [-1, 48, 96, 96]              96\n",
      "      FusedMBConv-19           [-1, 48, 96, 96]               0\n",
      "           Conv2d-20          [-1, 192, 96, 96]          82,944\n",
      "      BatchNorm2d-21          [-1, 192, 96, 96]             384\n",
      "             SiLU-22          [-1, 192, 96, 96]               0\n",
      "           Conv2d-23           [-1, 48, 96, 96]           9,216\n",
      "      BatchNorm2d-24           [-1, 48, 96, 96]              96\n",
      "  StochasticDepth-25           [-1, 48, 96, 96]               0\n",
      "      FusedMBConv-26           [-1, 48, 96, 96]               0\n",
      "           Conv2d-27          [-1, 192, 96, 96]          82,944\n",
      "      BatchNorm2d-28          [-1, 192, 96, 96]             384\n",
      "             SiLU-29          [-1, 192, 96, 96]               0\n",
      "           Conv2d-30           [-1, 48, 96, 96]           9,216\n",
      "      BatchNorm2d-31           [-1, 48, 96, 96]              96\n",
      "  StochasticDepth-32           [-1, 48, 96, 96]               0\n",
      "      FusedMBConv-33           [-1, 48, 96, 96]               0\n",
      "           Conv2d-34          [-1, 192, 96, 96]          82,944\n",
      "      BatchNorm2d-35          [-1, 192, 96, 96]             384\n",
      "             SiLU-36          [-1, 192, 96, 96]               0\n",
      "           Conv2d-37           [-1, 48, 96, 96]           9,216\n",
      "      BatchNorm2d-38           [-1, 48, 96, 96]              96\n",
      "  StochasticDepth-39           [-1, 48, 96, 96]               0\n",
      "      FusedMBConv-40           [-1, 48, 96, 96]               0\n",
      "           Conv2d-41          [-1, 192, 48, 48]          82,944\n",
      "      BatchNorm2d-42          [-1, 192, 48, 48]             384\n",
      "             SiLU-43          [-1, 192, 48, 48]               0\n",
      "           Conv2d-44           [-1, 64, 48, 48]          12,288\n",
      "      BatchNorm2d-45           [-1, 64, 48, 48]             128\n",
      "      FusedMBConv-46           [-1, 64, 48, 48]               0\n",
      "           Conv2d-47          [-1, 256, 48, 48]         147,456\n",
      "      BatchNorm2d-48          [-1, 256, 48, 48]             512\n",
      "             SiLU-49          [-1, 256, 48, 48]               0\n",
      "           Conv2d-50           [-1, 64, 48, 48]          16,384\n",
      "      BatchNorm2d-51           [-1, 64, 48, 48]             128\n",
      "  StochasticDepth-52           [-1, 64, 48, 48]               0\n",
      "      FusedMBConv-53           [-1, 64, 48, 48]               0\n",
      "           Conv2d-54          [-1, 256, 48, 48]         147,456\n",
      "      BatchNorm2d-55          [-1, 256, 48, 48]             512\n",
      "             SiLU-56          [-1, 256, 48, 48]               0\n",
      "           Conv2d-57           [-1, 64, 48, 48]          16,384\n",
      "      BatchNorm2d-58           [-1, 64, 48, 48]             128\n",
      "  StochasticDepth-59           [-1, 64, 48, 48]               0\n",
      "      FusedMBConv-60           [-1, 64, 48, 48]               0\n",
      "           Conv2d-61          [-1, 256, 48, 48]         147,456\n",
      "      BatchNorm2d-62          [-1, 256, 48, 48]             512\n",
      "             SiLU-63          [-1, 256, 48, 48]               0\n",
      "           Conv2d-64           [-1, 64, 48, 48]          16,384\n",
      "      BatchNorm2d-65           [-1, 64, 48, 48]             128\n",
      "  StochasticDepth-66           [-1, 64, 48, 48]               0\n",
      "      FusedMBConv-67           [-1, 64, 48, 48]               0\n",
      "           Conv2d-68          [-1, 256, 48, 48]          16,384\n",
      "      BatchNorm2d-69          [-1, 256, 48, 48]             512\n",
      "             SiLU-70          [-1, 256, 48, 48]               0\n",
      "           Conv2d-71          [-1, 256, 24, 24]           2,304\n",
      "      BatchNorm2d-72          [-1, 256, 24, 24]             512\n",
      "             SiLU-73          [-1, 256, 24, 24]               0\n",
      "AdaptiveAvgPool2d-74            [-1, 256, 1, 1]               0\n",
      "           Conv2d-75             [-1, 16, 1, 1]           4,112\n",
      "             SiLU-76             [-1, 16, 1, 1]               0\n",
      "           Conv2d-77            [-1, 256, 1, 1]           4,352\n",
      "          Sigmoid-78            [-1, 256, 1, 1]               0\n",
      "SqueezeExcitation-79          [-1, 256, 24, 24]               0\n",
      "           Conv2d-80          [-1, 128, 24, 24]          32,768\n",
      "      BatchNorm2d-81          [-1, 128, 24, 24]             256\n",
      "           MBConv-82          [-1, 128, 24, 24]               0\n",
      "           Conv2d-83          [-1, 512, 24, 24]          65,536\n",
      "      BatchNorm2d-84          [-1, 512, 24, 24]           1,024\n",
      "             SiLU-85          [-1, 512, 24, 24]               0\n",
      "           Conv2d-86          [-1, 512, 24, 24]           4,608\n",
      "      BatchNorm2d-87          [-1, 512, 24, 24]           1,024\n",
      "             SiLU-88          [-1, 512, 24, 24]               0\n",
      "AdaptiveAvgPool2d-89            [-1, 512, 1, 1]               0\n",
      "           Conv2d-90             [-1, 32, 1, 1]          16,416\n",
      "             SiLU-91             [-1, 32, 1, 1]               0\n",
      "           Conv2d-92            [-1, 512, 1, 1]          16,896\n",
      "          Sigmoid-93            [-1, 512, 1, 1]               0\n",
      "SqueezeExcitation-94          [-1, 512, 24, 24]               0\n",
      "           Conv2d-95          [-1, 128, 24, 24]          65,536\n",
      "      BatchNorm2d-96          [-1, 128, 24, 24]             256\n",
      "  StochasticDepth-97          [-1, 128, 24, 24]               0\n",
      "           MBConv-98          [-1, 128, 24, 24]               0\n",
      "           Conv2d-99          [-1, 512, 24, 24]          65,536\n",
      "     BatchNorm2d-100          [-1, 512, 24, 24]           1,024\n",
      "            SiLU-101          [-1, 512, 24, 24]               0\n",
      "          Conv2d-102          [-1, 512, 24, 24]           4,608\n",
      "     BatchNorm2d-103          [-1, 512, 24, 24]           1,024\n",
      "            SiLU-104          [-1, 512, 24, 24]               0\n",
      "AdaptiveAvgPool2d-105            [-1, 512, 1, 1]               0\n",
      "          Conv2d-106             [-1, 32, 1, 1]          16,416\n",
      "            SiLU-107             [-1, 32, 1, 1]               0\n",
      "          Conv2d-108            [-1, 512, 1, 1]          16,896\n",
      "         Sigmoid-109            [-1, 512, 1, 1]               0\n",
      "SqueezeExcitation-110          [-1, 512, 24, 24]               0\n",
      "          Conv2d-111          [-1, 128, 24, 24]          65,536\n",
      "     BatchNorm2d-112          [-1, 128, 24, 24]             256\n",
      " StochasticDepth-113          [-1, 128, 24, 24]               0\n",
      "          MBConv-114          [-1, 128, 24, 24]               0\n",
      "          Conv2d-115          [-1, 512, 24, 24]          65,536\n",
      "     BatchNorm2d-116          [-1, 512, 24, 24]           1,024\n",
      "            SiLU-117          [-1, 512, 24, 24]               0\n",
      "          Conv2d-118          [-1, 512, 24, 24]           4,608\n",
      "     BatchNorm2d-119          [-1, 512, 24, 24]           1,024\n",
      "            SiLU-120          [-1, 512, 24, 24]               0\n",
      "AdaptiveAvgPool2d-121            [-1, 512, 1, 1]               0\n",
      "          Conv2d-122             [-1, 32, 1, 1]          16,416\n",
      "            SiLU-123             [-1, 32, 1, 1]               0\n",
      "          Conv2d-124            [-1, 512, 1, 1]          16,896\n",
      "         Sigmoid-125            [-1, 512, 1, 1]               0\n",
      "SqueezeExcitation-126          [-1, 512, 24, 24]               0\n",
      "          Conv2d-127          [-1, 128, 24, 24]          65,536\n",
      "     BatchNorm2d-128          [-1, 128, 24, 24]             256\n",
      " StochasticDepth-129          [-1, 128, 24, 24]               0\n",
      "          MBConv-130          [-1, 128, 24, 24]               0\n",
      "          Conv2d-131          [-1, 512, 24, 24]          65,536\n",
      "     BatchNorm2d-132          [-1, 512, 24, 24]           1,024\n",
      "            SiLU-133          [-1, 512, 24, 24]               0\n",
      "          Conv2d-134          [-1, 512, 24, 24]           4,608\n",
      "     BatchNorm2d-135          [-1, 512, 24, 24]           1,024\n",
      "            SiLU-136          [-1, 512, 24, 24]               0\n",
      "AdaptiveAvgPool2d-137            [-1, 512, 1, 1]               0\n",
      "          Conv2d-138             [-1, 32, 1, 1]          16,416\n",
      "            SiLU-139             [-1, 32, 1, 1]               0\n",
      "          Conv2d-140            [-1, 512, 1, 1]          16,896\n",
      "         Sigmoid-141            [-1, 512, 1, 1]               0\n",
      "SqueezeExcitation-142          [-1, 512, 24, 24]               0\n",
      "          Conv2d-143          [-1, 128, 24, 24]          65,536\n",
      "     BatchNorm2d-144          [-1, 128, 24, 24]             256\n",
      " StochasticDepth-145          [-1, 128, 24, 24]               0\n",
      "          MBConv-146          [-1, 128, 24, 24]               0\n",
      "          Conv2d-147          [-1, 512, 24, 24]          65,536\n",
      "     BatchNorm2d-148          [-1, 512, 24, 24]           1,024\n",
      "            SiLU-149          [-1, 512, 24, 24]               0\n",
      "          Conv2d-150          [-1, 512, 24, 24]           4,608\n",
      "     BatchNorm2d-151          [-1, 512, 24, 24]           1,024\n",
      "            SiLU-152          [-1, 512, 24, 24]               0\n",
      "AdaptiveAvgPool2d-153            [-1, 512, 1, 1]               0\n",
      "          Conv2d-154             [-1, 32, 1, 1]          16,416\n",
      "            SiLU-155             [-1, 32, 1, 1]               0\n",
      "          Conv2d-156            [-1, 512, 1, 1]          16,896\n",
      "         Sigmoid-157            [-1, 512, 1, 1]               0\n",
      "SqueezeExcitation-158          [-1, 512, 24, 24]               0\n",
      "          Conv2d-159          [-1, 128, 24, 24]          65,536\n",
      "     BatchNorm2d-160          [-1, 128, 24, 24]             256\n",
      " StochasticDepth-161          [-1, 128, 24, 24]               0\n",
      "          MBConv-162          [-1, 128, 24, 24]               0\n",
      "          Conv2d-163          [-1, 768, 24, 24]          98,304\n",
      "     BatchNorm2d-164          [-1, 768, 24, 24]           1,536\n",
      "            SiLU-165          [-1, 768, 24, 24]               0\n",
      "          Conv2d-166          [-1, 768, 24, 24]           6,912\n",
      "     BatchNorm2d-167          [-1, 768, 24, 24]           1,536\n",
      "            SiLU-168          [-1, 768, 24, 24]               0\n",
      "AdaptiveAvgPool2d-169            [-1, 768, 1, 1]               0\n",
      "          Conv2d-170             [-1, 32, 1, 1]          24,608\n",
      "            SiLU-171             [-1, 32, 1, 1]               0\n",
      "          Conv2d-172            [-1, 768, 1, 1]          25,344\n",
      "         Sigmoid-173            [-1, 768, 1, 1]               0\n",
      "SqueezeExcitation-174          [-1, 768, 24, 24]               0\n",
      "          Conv2d-175          [-1, 160, 24, 24]         122,880\n",
      "     BatchNorm2d-176          [-1, 160, 24, 24]             320\n",
      "          MBConv-177          [-1, 160, 24, 24]               0\n",
      "          Conv2d-178          [-1, 960, 24, 24]         153,600\n",
      "     BatchNorm2d-179          [-1, 960, 24, 24]           1,920\n",
      "            SiLU-180          [-1, 960, 24, 24]               0\n",
      "          Conv2d-181          [-1, 960, 24, 24]           8,640\n",
      "     BatchNorm2d-182          [-1, 960, 24, 24]           1,920\n",
      "            SiLU-183          [-1, 960, 24, 24]               0\n",
      "AdaptiveAvgPool2d-184            [-1, 960, 1, 1]               0\n",
      "          Conv2d-185             [-1, 40, 1, 1]          38,440\n",
      "            SiLU-186             [-1, 40, 1, 1]               0\n",
      "          Conv2d-187            [-1, 960, 1, 1]          39,360\n",
      "         Sigmoid-188            [-1, 960, 1, 1]               0\n",
      "SqueezeExcitation-189          [-1, 960, 24, 24]               0\n",
      "          Conv2d-190          [-1, 160, 24, 24]         153,600\n",
      "     BatchNorm2d-191          [-1, 160, 24, 24]             320\n",
      " StochasticDepth-192          [-1, 160, 24, 24]               0\n",
      "          MBConv-193          [-1, 160, 24, 24]               0\n",
      "          Conv2d-194          [-1, 960, 24, 24]         153,600\n",
      "     BatchNorm2d-195          [-1, 960, 24, 24]           1,920\n",
      "            SiLU-196          [-1, 960, 24, 24]               0\n",
      "          Conv2d-197          [-1, 960, 24, 24]           8,640\n",
      "     BatchNorm2d-198          [-1, 960, 24, 24]           1,920\n",
      "            SiLU-199          [-1, 960, 24, 24]               0\n",
      "AdaptiveAvgPool2d-200            [-1, 960, 1, 1]               0\n",
      "          Conv2d-201             [-1, 40, 1, 1]          38,440\n",
      "            SiLU-202             [-1, 40, 1, 1]               0\n",
      "          Conv2d-203            [-1, 960, 1, 1]          39,360\n",
      "         Sigmoid-204            [-1, 960, 1, 1]               0\n",
      "SqueezeExcitation-205          [-1, 960, 24, 24]               0\n",
      "          Conv2d-206          [-1, 160, 24, 24]         153,600\n",
      "     BatchNorm2d-207          [-1, 160, 24, 24]             320\n",
      " StochasticDepth-208          [-1, 160, 24, 24]               0\n",
      "          MBConv-209          [-1, 160, 24, 24]               0\n",
      "          Conv2d-210          [-1, 960, 24, 24]         153,600\n",
      "     BatchNorm2d-211          [-1, 960, 24, 24]           1,920\n",
      "            SiLU-212          [-1, 960, 24, 24]               0\n",
      "          Conv2d-213          [-1, 960, 24, 24]           8,640\n",
      "     BatchNorm2d-214          [-1, 960, 24, 24]           1,920\n",
      "            SiLU-215          [-1, 960, 24, 24]               0\n",
      "AdaptiveAvgPool2d-216            [-1, 960, 1, 1]               0\n",
      "          Conv2d-217             [-1, 40, 1, 1]          38,440\n",
      "            SiLU-218             [-1, 40, 1, 1]               0\n",
      "          Conv2d-219            [-1, 960, 1, 1]          39,360\n",
      "         Sigmoid-220            [-1, 960, 1, 1]               0\n",
      "SqueezeExcitation-221          [-1, 960, 24, 24]               0\n",
      "          Conv2d-222          [-1, 160, 24, 24]         153,600\n",
      "     BatchNorm2d-223          [-1, 160, 24, 24]             320\n",
      " StochasticDepth-224          [-1, 160, 24, 24]               0\n",
      "          MBConv-225          [-1, 160, 24, 24]               0\n",
      "          Conv2d-226          [-1, 960, 24, 24]         153,600\n",
      "     BatchNorm2d-227          [-1, 960, 24, 24]           1,920\n",
      "            SiLU-228          [-1, 960, 24, 24]               0\n",
      "          Conv2d-229          [-1, 960, 24, 24]           8,640\n",
      "     BatchNorm2d-230          [-1, 960, 24, 24]           1,920\n",
      "            SiLU-231          [-1, 960, 24, 24]               0\n",
      "AdaptiveAvgPool2d-232            [-1, 960, 1, 1]               0\n",
      "          Conv2d-233             [-1, 40, 1, 1]          38,440\n",
      "            SiLU-234             [-1, 40, 1, 1]               0\n",
      "          Conv2d-235            [-1, 960, 1, 1]          39,360\n",
      "         Sigmoid-236            [-1, 960, 1, 1]               0\n",
      "SqueezeExcitation-237          [-1, 960, 24, 24]               0\n",
      "          Conv2d-238          [-1, 160, 24, 24]         153,600\n",
      "     BatchNorm2d-239          [-1, 160, 24, 24]             320\n",
      " StochasticDepth-240          [-1, 160, 24, 24]               0\n",
      "          MBConv-241          [-1, 160, 24, 24]               0\n",
      "          Conv2d-242          [-1, 960, 24, 24]         153,600\n",
      "     BatchNorm2d-243          [-1, 960, 24, 24]           1,920\n",
      "            SiLU-244          [-1, 960, 24, 24]               0\n",
      "          Conv2d-245          [-1, 960, 24, 24]           8,640\n",
      "     BatchNorm2d-246          [-1, 960, 24, 24]           1,920\n",
      "            SiLU-247          [-1, 960, 24, 24]               0\n",
      "AdaptiveAvgPool2d-248            [-1, 960, 1, 1]               0\n",
      "          Conv2d-249             [-1, 40, 1, 1]          38,440\n",
      "            SiLU-250             [-1, 40, 1, 1]               0\n",
      "          Conv2d-251            [-1, 960, 1, 1]          39,360\n",
      "         Sigmoid-252            [-1, 960, 1, 1]               0\n",
      "SqueezeExcitation-253          [-1, 960, 24, 24]               0\n",
      "          Conv2d-254          [-1, 160, 24, 24]         153,600\n",
      "     BatchNorm2d-255          [-1, 160, 24, 24]             320\n",
      " StochasticDepth-256          [-1, 160, 24, 24]               0\n",
      "          MBConv-257          [-1, 160, 24, 24]               0\n",
      "          Conv2d-258          [-1, 960, 24, 24]         153,600\n",
      "     BatchNorm2d-259          [-1, 960, 24, 24]           1,920\n",
      "            SiLU-260          [-1, 960, 24, 24]               0\n",
      "          Conv2d-261          [-1, 960, 24, 24]           8,640\n",
      "     BatchNorm2d-262          [-1, 960, 24, 24]           1,920\n",
      "            SiLU-263          [-1, 960, 24, 24]               0\n",
      "AdaptiveAvgPool2d-264            [-1, 960, 1, 1]               0\n",
      "          Conv2d-265             [-1, 40, 1, 1]          38,440\n",
      "            SiLU-266             [-1, 40, 1, 1]               0\n",
      "          Conv2d-267            [-1, 960, 1, 1]          39,360\n",
      "         Sigmoid-268            [-1, 960, 1, 1]               0\n",
      "SqueezeExcitation-269          [-1, 960, 24, 24]               0\n",
      "          Conv2d-270          [-1, 160, 24, 24]         153,600\n",
      "     BatchNorm2d-271          [-1, 160, 24, 24]             320\n",
      " StochasticDepth-272          [-1, 160, 24, 24]               0\n",
      "          MBConv-273          [-1, 160, 24, 24]               0\n",
      "          Conv2d-274          [-1, 960, 24, 24]         153,600\n",
      "     BatchNorm2d-275          [-1, 960, 24, 24]           1,920\n",
      "            SiLU-276          [-1, 960, 24, 24]               0\n",
      "          Conv2d-277          [-1, 960, 24, 24]           8,640\n",
      "     BatchNorm2d-278          [-1, 960, 24, 24]           1,920\n",
      "            SiLU-279          [-1, 960, 24, 24]               0\n",
      "AdaptiveAvgPool2d-280            [-1, 960, 1, 1]               0\n",
      "          Conv2d-281             [-1, 40, 1, 1]          38,440\n",
      "            SiLU-282             [-1, 40, 1, 1]               0\n",
      "          Conv2d-283            [-1, 960, 1, 1]          39,360\n",
      "         Sigmoid-284            [-1, 960, 1, 1]               0\n",
      "SqueezeExcitation-285          [-1, 960, 24, 24]               0\n",
      "          Conv2d-286          [-1, 160, 24, 24]         153,600\n",
      "     BatchNorm2d-287          [-1, 160, 24, 24]             320\n",
      " StochasticDepth-288          [-1, 160, 24, 24]               0\n",
      "          MBConv-289          [-1, 160, 24, 24]               0\n",
      "          Conv2d-290          [-1, 960, 24, 24]         153,600\n",
      "     BatchNorm2d-291          [-1, 960, 24, 24]           1,920\n",
      "            SiLU-292          [-1, 960, 24, 24]               0\n",
      "          Conv2d-293          [-1, 960, 24, 24]           8,640\n",
      "     BatchNorm2d-294          [-1, 960, 24, 24]           1,920\n",
      "            SiLU-295          [-1, 960, 24, 24]               0\n",
      "AdaptiveAvgPool2d-296            [-1, 960, 1, 1]               0\n",
      "          Conv2d-297             [-1, 40, 1, 1]          38,440\n",
      "            SiLU-298             [-1, 40, 1, 1]               0\n",
      "          Conv2d-299            [-1, 960, 1, 1]          39,360\n",
      "         Sigmoid-300            [-1, 960, 1, 1]               0\n",
      "SqueezeExcitation-301          [-1, 960, 24, 24]               0\n",
      "          Conv2d-302          [-1, 160, 24, 24]         153,600\n",
      "     BatchNorm2d-303          [-1, 160, 24, 24]             320\n",
      " StochasticDepth-304          [-1, 160, 24, 24]               0\n",
      "          MBConv-305          [-1, 160, 24, 24]               0\n",
      "          Conv2d-306          [-1, 960, 24, 24]         153,600\n",
      "     BatchNorm2d-307          [-1, 960, 24, 24]           1,920\n",
      "            SiLU-308          [-1, 960, 24, 24]               0\n",
      "          Conv2d-309          [-1, 960, 12, 12]           8,640\n",
      "     BatchNorm2d-310          [-1, 960, 12, 12]           1,920\n",
      "            SiLU-311          [-1, 960, 12, 12]               0\n",
      "AdaptiveAvgPool2d-312            [-1, 960, 1, 1]               0\n",
      "          Conv2d-313             [-1, 40, 1, 1]          38,440\n",
      "            SiLU-314             [-1, 40, 1, 1]               0\n",
      "          Conv2d-315            [-1, 960, 1, 1]          39,360\n",
      "         Sigmoid-316            [-1, 960, 1, 1]               0\n",
      "SqueezeExcitation-317          [-1, 960, 12, 12]               0\n",
      "          Conv2d-318          [-1, 256, 12, 12]         245,760\n",
      "     BatchNorm2d-319          [-1, 256, 12, 12]             512\n",
      "          MBConv-320          [-1, 256, 12, 12]               0\n",
      "          Conv2d-321         [-1, 1536, 12, 12]         393,216\n",
      "     BatchNorm2d-322         [-1, 1536, 12, 12]           3,072\n",
      "            SiLU-323         [-1, 1536, 12, 12]               0\n",
      "          Conv2d-324         [-1, 1536, 12, 12]          13,824\n",
      "     BatchNorm2d-325         [-1, 1536, 12, 12]           3,072\n",
      "            SiLU-326         [-1, 1536, 12, 12]               0\n",
      "AdaptiveAvgPool2d-327           [-1, 1536, 1, 1]               0\n",
      "          Conv2d-328             [-1, 64, 1, 1]          98,368\n",
      "            SiLU-329             [-1, 64, 1, 1]               0\n",
      "          Conv2d-330           [-1, 1536, 1, 1]          99,840\n",
      "         Sigmoid-331           [-1, 1536, 1, 1]               0\n",
      "SqueezeExcitation-332         [-1, 1536, 12, 12]               0\n",
      "          Conv2d-333          [-1, 256, 12, 12]         393,216\n",
      "     BatchNorm2d-334          [-1, 256, 12, 12]             512\n",
      " StochasticDepth-335          [-1, 256, 12, 12]               0\n",
      "          MBConv-336          [-1, 256, 12, 12]               0\n",
      "          Conv2d-337         [-1, 1536, 12, 12]         393,216\n",
      "     BatchNorm2d-338         [-1, 1536, 12, 12]           3,072\n",
      "            SiLU-339         [-1, 1536, 12, 12]               0\n",
      "          Conv2d-340         [-1, 1536, 12, 12]          13,824\n",
      "     BatchNorm2d-341         [-1, 1536, 12, 12]           3,072\n",
      "            SiLU-342         [-1, 1536, 12, 12]               0\n",
      "AdaptiveAvgPool2d-343           [-1, 1536, 1, 1]               0\n",
      "          Conv2d-344             [-1, 64, 1, 1]          98,368\n",
      "            SiLU-345             [-1, 64, 1, 1]               0\n",
      "          Conv2d-346           [-1, 1536, 1, 1]          99,840\n",
      "         Sigmoid-347           [-1, 1536, 1, 1]               0\n",
      "SqueezeExcitation-348         [-1, 1536, 12, 12]               0\n",
      "          Conv2d-349          [-1, 256, 12, 12]         393,216\n",
      "     BatchNorm2d-350          [-1, 256, 12, 12]             512\n",
      " StochasticDepth-351          [-1, 256, 12, 12]               0\n",
      "          MBConv-352          [-1, 256, 12, 12]               0\n",
      "          Conv2d-353         [-1, 1536, 12, 12]         393,216\n",
      "     BatchNorm2d-354         [-1, 1536, 12, 12]           3,072\n",
      "            SiLU-355         [-1, 1536, 12, 12]               0\n",
      "          Conv2d-356         [-1, 1536, 12, 12]          13,824\n",
      "     BatchNorm2d-357         [-1, 1536, 12, 12]           3,072\n",
      "            SiLU-358         [-1, 1536, 12, 12]               0\n",
      "AdaptiveAvgPool2d-359           [-1, 1536, 1, 1]               0\n",
      "          Conv2d-360             [-1, 64, 1, 1]          98,368\n",
      "            SiLU-361             [-1, 64, 1, 1]               0\n",
      "          Conv2d-362           [-1, 1536, 1, 1]          99,840\n",
      "         Sigmoid-363           [-1, 1536, 1, 1]               0\n",
      "SqueezeExcitation-364         [-1, 1536, 12, 12]               0\n",
      "          Conv2d-365          [-1, 256, 12, 12]         393,216\n",
      "     BatchNorm2d-366          [-1, 256, 12, 12]             512\n",
      " StochasticDepth-367          [-1, 256, 12, 12]               0\n",
      "          MBConv-368          [-1, 256, 12, 12]               0\n",
      "          Conv2d-369         [-1, 1536, 12, 12]         393,216\n",
      "     BatchNorm2d-370         [-1, 1536, 12, 12]           3,072\n",
      "            SiLU-371         [-1, 1536, 12, 12]               0\n",
      "          Conv2d-372         [-1, 1536, 12, 12]          13,824\n",
      "     BatchNorm2d-373         [-1, 1536, 12, 12]           3,072\n",
      "            SiLU-374         [-1, 1536, 12, 12]               0\n",
      "AdaptiveAvgPool2d-375           [-1, 1536, 1, 1]               0\n",
      "          Conv2d-376             [-1, 64, 1, 1]          98,368\n",
      "            SiLU-377             [-1, 64, 1, 1]               0\n",
      "          Conv2d-378           [-1, 1536, 1, 1]          99,840\n",
      "         Sigmoid-379           [-1, 1536, 1, 1]               0\n",
      "SqueezeExcitation-380         [-1, 1536, 12, 12]               0\n",
      "          Conv2d-381          [-1, 256, 12, 12]         393,216\n",
      "     BatchNorm2d-382          [-1, 256, 12, 12]             512\n",
      " StochasticDepth-383          [-1, 256, 12, 12]               0\n",
      "          MBConv-384          [-1, 256, 12, 12]               0\n",
      "          Conv2d-385         [-1, 1536, 12, 12]         393,216\n",
      "     BatchNorm2d-386         [-1, 1536, 12, 12]           3,072\n",
      "            SiLU-387         [-1, 1536, 12, 12]               0\n",
      "          Conv2d-388         [-1, 1536, 12, 12]          13,824\n",
      "     BatchNorm2d-389         [-1, 1536, 12, 12]           3,072\n",
      "            SiLU-390         [-1, 1536, 12, 12]               0\n",
      "AdaptiveAvgPool2d-391           [-1, 1536, 1, 1]               0\n",
      "          Conv2d-392             [-1, 64, 1, 1]          98,368\n",
      "            SiLU-393             [-1, 64, 1, 1]               0\n",
      "          Conv2d-394           [-1, 1536, 1, 1]          99,840\n",
      "         Sigmoid-395           [-1, 1536, 1, 1]               0\n",
      "SqueezeExcitation-396         [-1, 1536, 12, 12]               0\n",
      "          Conv2d-397          [-1, 256, 12, 12]         393,216\n",
      "     BatchNorm2d-398          [-1, 256, 12, 12]             512\n",
      " StochasticDepth-399          [-1, 256, 12, 12]               0\n",
      "          MBConv-400          [-1, 256, 12, 12]               0\n",
      "          Conv2d-401         [-1, 1536, 12, 12]         393,216\n",
      "     BatchNorm2d-402         [-1, 1536, 12, 12]           3,072\n",
      "            SiLU-403         [-1, 1536, 12, 12]               0\n",
      "          Conv2d-404         [-1, 1536, 12, 12]          13,824\n",
      "     BatchNorm2d-405         [-1, 1536, 12, 12]           3,072\n",
      "            SiLU-406         [-1, 1536, 12, 12]               0\n",
      "AdaptiveAvgPool2d-407           [-1, 1536, 1, 1]               0\n",
      "          Conv2d-408             [-1, 64, 1, 1]          98,368\n",
      "            SiLU-409             [-1, 64, 1, 1]               0\n",
      "          Conv2d-410           [-1, 1536, 1, 1]          99,840\n",
      "         Sigmoid-411           [-1, 1536, 1, 1]               0\n",
      "SqueezeExcitation-412         [-1, 1536, 12, 12]               0\n",
      "          Conv2d-413          [-1, 256, 12, 12]         393,216\n",
      "     BatchNorm2d-414          [-1, 256, 12, 12]             512\n",
      " StochasticDepth-415          [-1, 256, 12, 12]               0\n",
      "          MBConv-416          [-1, 256, 12, 12]               0\n",
      "          Conv2d-417         [-1, 1536, 12, 12]         393,216\n",
      "     BatchNorm2d-418         [-1, 1536, 12, 12]           3,072\n",
      "            SiLU-419         [-1, 1536, 12, 12]               0\n",
      "          Conv2d-420         [-1, 1536, 12, 12]          13,824\n",
      "     BatchNorm2d-421         [-1, 1536, 12, 12]           3,072\n",
      "            SiLU-422         [-1, 1536, 12, 12]               0\n",
      "AdaptiveAvgPool2d-423           [-1, 1536, 1, 1]               0\n",
      "          Conv2d-424             [-1, 64, 1, 1]          98,368\n",
      "            SiLU-425             [-1, 64, 1, 1]               0\n",
      "          Conv2d-426           [-1, 1536, 1, 1]          99,840\n",
      "         Sigmoid-427           [-1, 1536, 1, 1]               0\n",
      "SqueezeExcitation-428         [-1, 1536, 12, 12]               0\n",
      "          Conv2d-429          [-1, 256, 12, 12]         393,216\n",
      "     BatchNorm2d-430          [-1, 256, 12, 12]             512\n",
      " StochasticDepth-431          [-1, 256, 12, 12]               0\n",
      "          MBConv-432          [-1, 256, 12, 12]               0\n",
      "          Conv2d-433         [-1, 1536, 12, 12]         393,216\n",
      "     BatchNorm2d-434         [-1, 1536, 12, 12]           3,072\n",
      "            SiLU-435         [-1, 1536, 12, 12]               0\n",
      "          Conv2d-436         [-1, 1536, 12, 12]          13,824\n",
      "     BatchNorm2d-437         [-1, 1536, 12, 12]           3,072\n",
      "            SiLU-438         [-1, 1536, 12, 12]               0\n",
      "AdaptiveAvgPool2d-439           [-1, 1536, 1, 1]               0\n",
      "          Conv2d-440             [-1, 64, 1, 1]          98,368\n",
      "            SiLU-441             [-1, 64, 1, 1]               0\n",
      "          Conv2d-442           [-1, 1536, 1, 1]          99,840\n",
      "         Sigmoid-443           [-1, 1536, 1, 1]               0\n",
      "SqueezeExcitation-444         [-1, 1536, 12, 12]               0\n",
      "          Conv2d-445          [-1, 256, 12, 12]         393,216\n",
      "     BatchNorm2d-446          [-1, 256, 12, 12]             512\n",
      " StochasticDepth-447          [-1, 256, 12, 12]               0\n",
      "          MBConv-448          [-1, 256, 12, 12]               0\n",
      "          Conv2d-449         [-1, 1536, 12, 12]         393,216\n",
      "     BatchNorm2d-450         [-1, 1536, 12, 12]           3,072\n",
      "            SiLU-451         [-1, 1536, 12, 12]               0\n",
      "          Conv2d-452         [-1, 1536, 12, 12]          13,824\n",
      "     BatchNorm2d-453         [-1, 1536, 12, 12]           3,072\n",
      "            SiLU-454         [-1, 1536, 12, 12]               0\n",
      "AdaptiveAvgPool2d-455           [-1, 1536, 1, 1]               0\n",
      "          Conv2d-456             [-1, 64, 1, 1]          98,368\n",
      "            SiLU-457             [-1, 64, 1, 1]               0\n",
      "          Conv2d-458           [-1, 1536, 1, 1]          99,840\n",
      "         Sigmoid-459           [-1, 1536, 1, 1]               0\n",
      "SqueezeExcitation-460         [-1, 1536, 12, 12]               0\n",
      "          Conv2d-461          [-1, 256, 12, 12]         393,216\n",
      "     BatchNorm2d-462          [-1, 256, 12, 12]             512\n",
      " StochasticDepth-463          [-1, 256, 12, 12]               0\n",
      "          MBConv-464          [-1, 256, 12, 12]               0\n",
      "          Conv2d-465         [-1, 1536, 12, 12]         393,216\n",
      "     BatchNorm2d-466         [-1, 1536, 12, 12]           3,072\n",
      "            SiLU-467         [-1, 1536, 12, 12]               0\n",
      "          Conv2d-468         [-1, 1536, 12, 12]          13,824\n",
      "     BatchNorm2d-469         [-1, 1536, 12, 12]           3,072\n",
      "            SiLU-470         [-1, 1536, 12, 12]               0\n",
      "AdaptiveAvgPool2d-471           [-1, 1536, 1, 1]               0\n",
      "          Conv2d-472             [-1, 64, 1, 1]          98,368\n",
      "            SiLU-473             [-1, 64, 1, 1]               0\n",
      "          Conv2d-474           [-1, 1536, 1, 1]          99,840\n",
      "         Sigmoid-475           [-1, 1536, 1, 1]               0\n",
      "SqueezeExcitation-476         [-1, 1536, 12, 12]               0\n",
      "          Conv2d-477          [-1, 256, 12, 12]         393,216\n",
      "     BatchNorm2d-478          [-1, 256, 12, 12]             512\n",
      " StochasticDepth-479          [-1, 256, 12, 12]               0\n",
      "          MBConv-480          [-1, 256, 12, 12]               0\n",
      "          Conv2d-481         [-1, 1536, 12, 12]         393,216\n",
      "     BatchNorm2d-482         [-1, 1536, 12, 12]           3,072\n",
      "            SiLU-483         [-1, 1536, 12, 12]               0\n",
      "          Conv2d-484         [-1, 1536, 12, 12]          13,824\n",
      "     BatchNorm2d-485         [-1, 1536, 12, 12]           3,072\n",
      "            SiLU-486         [-1, 1536, 12, 12]               0\n",
      "AdaptiveAvgPool2d-487           [-1, 1536, 1, 1]               0\n",
      "          Conv2d-488             [-1, 64, 1, 1]          98,368\n",
      "            SiLU-489             [-1, 64, 1, 1]               0\n",
      "          Conv2d-490           [-1, 1536, 1, 1]          99,840\n",
      "         Sigmoid-491           [-1, 1536, 1, 1]               0\n",
      "SqueezeExcitation-492         [-1, 1536, 12, 12]               0\n",
      "          Conv2d-493          [-1, 256, 12, 12]         393,216\n",
      "     BatchNorm2d-494          [-1, 256, 12, 12]             512\n",
      " StochasticDepth-495          [-1, 256, 12, 12]               0\n",
      "          MBConv-496          [-1, 256, 12, 12]               0\n",
      "          Conv2d-497         [-1, 1536, 12, 12]         393,216\n",
      "     BatchNorm2d-498         [-1, 1536, 12, 12]           3,072\n",
      "            SiLU-499         [-1, 1536, 12, 12]               0\n",
      "          Conv2d-500         [-1, 1536, 12, 12]          13,824\n",
      "     BatchNorm2d-501         [-1, 1536, 12, 12]           3,072\n",
      "            SiLU-502         [-1, 1536, 12, 12]               0\n",
      "AdaptiveAvgPool2d-503           [-1, 1536, 1, 1]               0\n",
      "          Conv2d-504             [-1, 64, 1, 1]          98,368\n",
      "            SiLU-505             [-1, 64, 1, 1]               0\n",
      "          Conv2d-506           [-1, 1536, 1, 1]          99,840\n",
      "         Sigmoid-507           [-1, 1536, 1, 1]               0\n",
      "SqueezeExcitation-508         [-1, 1536, 12, 12]               0\n",
      "          Conv2d-509          [-1, 256, 12, 12]         393,216\n",
      "     BatchNorm2d-510          [-1, 256, 12, 12]             512\n",
      " StochasticDepth-511          [-1, 256, 12, 12]               0\n",
      "          MBConv-512          [-1, 256, 12, 12]               0\n",
      "          Conv2d-513         [-1, 1536, 12, 12]         393,216\n",
      "     BatchNorm2d-514         [-1, 1536, 12, 12]           3,072\n",
      "            SiLU-515         [-1, 1536, 12, 12]               0\n",
      "          Conv2d-516         [-1, 1536, 12, 12]          13,824\n",
      "     BatchNorm2d-517         [-1, 1536, 12, 12]           3,072\n",
      "            SiLU-518         [-1, 1536, 12, 12]               0\n",
      "AdaptiveAvgPool2d-519           [-1, 1536, 1, 1]               0\n",
      "          Conv2d-520             [-1, 64, 1, 1]          98,368\n",
      "            SiLU-521             [-1, 64, 1, 1]               0\n",
      "          Conv2d-522           [-1, 1536, 1, 1]          99,840\n",
      "         Sigmoid-523           [-1, 1536, 1, 1]               0\n",
      "SqueezeExcitation-524         [-1, 1536, 12, 12]               0\n",
      "          Conv2d-525          [-1, 256, 12, 12]         393,216\n",
      "     BatchNorm2d-526          [-1, 256, 12, 12]             512\n",
      " StochasticDepth-527          [-1, 256, 12, 12]               0\n",
      "          MBConv-528          [-1, 256, 12, 12]               0\n",
      "          Conv2d-529         [-1, 1536, 12, 12]         393,216\n",
      "     BatchNorm2d-530         [-1, 1536, 12, 12]           3,072\n",
      "            SiLU-531         [-1, 1536, 12, 12]               0\n",
      "          Conv2d-532         [-1, 1536, 12, 12]          13,824\n",
      "     BatchNorm2d-533         [-1, 1536, 12, 12]           3,072\n",
      "            SiLU-534         [-1, 1536, 12, 12]               0\n",
      "AdaptiveAvgPool2d-535           [-1, 1536, 1, 1]               0\n",
      "          Conv2d-536             [-1, 64, 1, 1]          98,368\n",
      "            SiLU-537             [-1, 64, 1, 1]               0\n",
      "          Conv2d-538           [-1, 1536, 1, 1]          99,840\n",
      "         Sigmoid-539           [-1, 1536, 1, 1]               0\n",
      "SqueezeExcitation-540         [-1, 1536, 12, 12]               0\n",
      "          Conv2d-541          [-1, 256, 12, 12]         393,216\n",
      "     BatchNorm2d-542          [-1, 256, 12, 12]             512\n",
      " StochasticDepth-543          [-1, 256, 12, 12]               0\n",
      "          MBConv-544          [-1, 256, 12, 12]               0\n",
      "          Conv2d-545         [-1, 1280, 12, 12]         327,680\n",
      "     BatchNorm2d-546         [-1, 1280, 12, 12]           2,560\n",
      "            SiLU-547         [-1, 1280, 12, 12]               0\n",
      "AdaptiveAvgPool2d-548           [-1, 1280, 1, 1]               0\n",
      "         Dropout-549                 [-1, 1280]               0\n",
      "            ReLU-550                 [-1, 1280]               0\n",
      "          Linear-551                   [-1, 28]          35,868\n",
      "================================================================\n",
      "Total params: 20,213,356\n",
      "Trainable params: 20,213,356\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.69\n",
      "Forward/backward pass size (MB): 945.68\n",
      "Params size (MB): 77.11\n",
      "Estimated Total Size (MB): 1024.48\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(efficientnet_model.to('cuda'), (3,384,384))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 96, 65, 65]           4,704\n",
      "           Permute-2           [-1, 65, 65, 96]               0\n",
      "         LayerNorm-3           [-1, 65, 65, 96]             192\n",
      "            Linear-4          [-1, 15, 15, 512]           1,536\n",
      "              ReLU-5          [-1, 15, 15, 512]               0\n",
      "            Linear-6            [-1, 15, 15, 3]           1,536\n",
      "ShiftedWindowAttentionV2-7           [-1, 65, 65, 96]               0\n",
      "         LayerNorm-8           [-1, 65, 65, 96]             192\n",
      "   StochasticDepth-9           [-1, 65, 65, 96]               0\n",
      "           Linear-10          [-1, 65, 65, 384]          37,248\n",
      "             GELU-11          [-1, 65, 65, 384]               0\n",
      "          Dropout-12          [-1, 65, 65, 384]               0\n",
      "           Linear-13           [-1, 65, 65, 96]          36,960\n",
      "          Dropout-14           [-1, 65, 65, 96]               0\n",
      "        LayerNorm-15           [-1, 65, 65, 96]             192\n",
      "  StochasticDepth-16           [-1, 65, 65, 96]               0\n",
      "SwinTransformerBlockV2-17           [-1, 65, 65, 96]               0\n",
      "           Linear-18          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-19          [-1, 15, 15, 512]               0\n",
      "           Linear-20            [-1, 15, 15, 3]           1,536\n",
      "ShiftedWindowAttentionV2-21           [-1, 65, 65, 96]               0\n",
      "        LayerNorm-22           [-1, 65, 65, 96]             192\n",
      "  StochasticDepth-23           [-1, 65, 65, 96]               0\n",
      "           Linear-24          [-1, 65, 65, 384]          37,248\n",
      "             GELU-25          [-1, 65, 65, 384]               0\n",
      "          Dropout-26          [-1, 65, 65, 384]               0\n",
      "           Linear-27           [-1, 65, 65, 96]          36,960\n",
      "          Dropout-28           [-1, 65, 65, 96]               0\n",
      "        LayerNorm-29           [-1, 65, 65, 96]             192\n",
      "  StochasticDepth-30           [-1, 65, 65, 96]               0\n",
      "SwinTransformerBlockV2-31           [-1, 65, 65, 96]               0\n",
      "           Linear-32          [-1, 33, 33, 192]          73,728\n",
      "        LayerNorm-33          [-1, 33, 33, 192]             384\n",
      "   PatchMergingV2-34          [-1, 33, 33, 192]               0\n",
      "           Linear-35          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-36          [-1, 15, 15, 512]               0\n",
      "           Linear-37            [-1, 15, 15, 6]           3,072\n",
      "ShiftedWindowAttentionV2-38          [-1, 33, 33, 192]               0\n",
      "        LayerNorm-39          [-1, 33, 33, 192]             384\n",
      "  StochasticDepth-40          [-1, 33, 33, 192]               0\n",
      "           Linear-41          [-1, 33, 33, 768]         148,224\n",
      "             GELU-42          [-1, 33, 33, 768]               0\n",
      "          Dropout-43          [-1, 33, 33, 768]               0\n",
      "           Linear-44          [-1, 33, 33, 192]         147,648\n",
      "          Dropout-45          [-1, 33, 33, 192]               0\n",
      "        LayerNorm-46          [-1, 33, 33, 192]             384\n",
      "  StochasticDepth-47          [-1, 33, 33, 192]               0\n",
      "SwinTransformerBlockV2-48          [-1, 33, 33, 192]               0\n",
      "           Linear-49          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-50          [-1, 15, 15, 512]               0\n",
      "           Linear-51            [-1, 15, 15, 6]           3,072\n",
      "ShiftedWindowAttentionV2-52          [-1, 33, 33, 192]               0\n",
      "        LayerNorm-53          [-1, 33, 33, 192]             384\n",
      "  StochasticDepth-54          [-1, 33, 33, 192]               0\n",
      "           Linear-55          [-1, 33, 33, 768]         148,224\n",
      "             GELU-56          [-1, 33, 33, 768]               0\n",
      "          Dropout-57          [-1, 33, 33, 768]               0\n",
      "           Linear-58          [-1, 33, 33, 192]         147,648\n",
      "          Dropout-59          [-1, 33, 33, 192]               0\n",
      "        LayerNorm-60          [-1, 33, 33, 192]             384\n",
      "  StochasticDepth-61          [-1, 33, 33, 192]               0\n",
      "SwinTransformerBlockV2-62          [-1, 33, 33, 192]               0\n",
      "           Linear-63          [-1, 17, 17, 384]         294,912\n",
      "        LayerNorm-64          [-1, 17, 17, 384]             768\n",
      "   PatchMergingV2-65          [-1, 17, 17, 384]               0\n",
      "           Linear-66          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-67          [-1, 15, 15, 512]               0\n",
      "           Linear-68           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-69          [-1, 17, 17, 384]               0\n",
      "        LayerNorm-70          [-1, 17, 17, 384]             768\n",
      "  StochasticDepth-71          [-1, 17, 17, 384]               0\n",
      "           Linear-72         [-1, 17, 17, 1536]         591,360\n",
      "             GELU-73         [-1, 17, 17, 1536]               0\n",
      "          Dropout-74         [-1, 17, 17, 1536]               0\n",
      "           Linear-75          [-1, 17, 17, 384]         590,208\n",
      "          Dropout-76          [-1, 17, 17, 384]               0\n",
      "        LayerNorm-77          [-1, 17, 17, 384]             768\n",
      "  StochasticDepth-78          [-1, 17, 17, 384]               0\n",
      "SwinTransformerBlockV2-79          [-1, 17, 17, 384]               0\n",
      "           Linear-80          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-81          [-1, 15, 15, 512]               0\n",
      "           Linear-82           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-83          [-1, 17, 17, 384]               0\n",
      "        LayerNorm-84          [-1, 17, 17, 384]             768\n",
      "  StochasticDepth-85          [-1, 17, 17, 384]               0\n",
      "           Linear-86         [-1, 17, 17, 1536]         591,360\n",
      "             GELU-87         [-1, 17, 17, 1536]               0\n",
      "          Dropout-88         [-1, 17, 17, 1536]               0\n",
      "           Linear-89          [-1, 17, 17, 384]         590,208\n",
      "          Dropout-90          [-1, 17, 17, 384]               0\n",
      "        LayerNorm-91          [-1, 17, 17, 384]             768\n",
      "  StochasticDepth-92          [-1, 17, 17, 384]               0\n",
      "SwinTransformerBlockV2-93          [-1, 17, 17, 384]               0\n",
      "           Linear-94          [-1, 15, 15, 512]           1,536\n",
      "             ReLU-95          [-1, 15, 15, 512]               0\n",
      "           Linear-96           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-97          [-1, 17, 17, 384]               0\n",
      "        LayerNorm-98          [-1, 17, 17, 384]             768\n",
      "  StochasticDepth-99          [-1, 17, 17, 384]               0\n",
      "          Linear-100         [-1, 17, 17, 1536]         591,360\n",
      "            GELU-101         [-1, 17, 17, 1536]               0\n",
      "         Dropout-102         [-1, 17, 17, 1536]               0\n",
      "          Linear-103          [-1, 17, 17, 384]         590,208\n",
      "         Dropout-104          [-1, 17, 17, 384]               0\n",
      "       LayerNorm-105          [-1, 17, 17, 384]             768\n",
      " StochasticDepth-106          [-1, 17, 17, 384]               0\n",
      "SwinTransformerBlockV2-107          [-1, 17, 17, 384]               0\n",
      "          Linear-108          [-1, 15, 15, 512]           1,536\n",
      "            ReLU-109          [-1, 15, 15, 512]               0\n",
      "          Linear-110           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-111          [-1, 17, 17, 384]               0\n",
      "       LayerNorm-112          [-1, 17, 17, 384]             768\n",
      " StochasticDepth-113          [-1, 17, 17, 384]               0\n",
      "          Linear-114         [-1, 17, 17, 1536]         591,360\n",
      "            GELU-115         [-1, 17, 17, 1536]               0\n",
      "         Dropout-116         [-1, 17, 17, 1536]               0\n",
      "          Linear-117          [-1, 17, 17, 384]         590,208\n",
      "         Dropout-118          [-1, 17, 17, 384]               0\n",
      "       LayerNorm-119          [-1, 17, 17, 384]             768\n",
      " StochasticDepth-120          [-1, 17, 17, 384]               0\n",
      "SwinTransformerBlockV2-121          [-1, 17, 17, 384]               0\n",
      "          Linear-122          [-1, 15, 15, 512]           1,536\n",
      "            ReLU-123          [-1, 15, 15, 512]               0\n",
      "          Linear-124           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-125          [-1, 17, 17, 384]               0\n",
      "       LayerNorm-126          [-1, 17, 17, 384]             768\n",
      " StochasticDepth-127          [-1, 17, 17, 384]               0\n",
      "          Linear-128         [-1, 17, 17, 1536]         591,360\n",
      "            GELU-129         [-1, 17, 17, 1536]               0\n",
      "         Dropout-130         [-1, 17, 17, 1536]               0\n",
      "          Linear-131          [-1, 17, 17, 384]         590,208\n",
      "         Dropout-132          [-1, 17, 17, 384]               0\n",
      "       LayerNorm-133          [-1, 17, 17, 384]             768\n",
      " StochasticDepth-134          [-1, 17, 17, 384]               0\n",
      "SwinTransformerBlockV2-135          [-1, 17, 17, 384]               0\n",
      "          Linear-136          [-1, 15, 15, 512]           1,536\n",
      "            ReLU-137          [-1, 15, 15, 512]               0\n",
      "          Linear-138           [-1, 15, 15, 12]           6,144\n",
      "ShiftedWindowAttentionV2-139          [-1, 17, 17, 384]               0\n",
      "       LayerNorm-140          [-1, 17, 17, 384]             768\n",
      " StochasticDepth-141          [-1, 17, 17, 384]               0\n",
      "          Linear-142         [-1, 17, 17, 1536]         591,360\n",
      "            GELU-143         [-1, 17, 17, 1536]               0\n",
      "         Dropout-144         [-1, 17, 17, 1536]               0\n",
      "          Linear-145          [-1, 17, 17, 384]         590,208\n",
      "         Dropout-146          [-1, 17, 17, 384]               0\n",
      "       LayerNorm-147          [-1, 17, 17, 384]             768\n",
      " StochasticDepth-148          [-1, 17, 17, 384]               0\n",
      "SwinTransformerBlockV2-149          [-1, 17, 17, 384]               0\n",
      "          Linear-150            [-1, 9, 9, 768]       1,179,648\n",
      "       LayerNorm-151            [-1, 9, 9, 768]           1,536\n",
      "  PatchMergingV2-152            [-1, 9, 9, 768]               0\n",
      "          Linear-153          [-1, 15, 15, 512]           1,536\n",
      "            ReLU-154          [-1, 15, 15, 512]               0\n",
      "          Linear-155           [-1, 15, 15, 24]          12,288\n",
      "ShiftedWindowAttentionV2-156            [-1, 9, 9, 768]               0\n",
      "       LayerNorm-157            [-1, 9, 9, 768]           1,536\n",
      " StochasticDepth-158            [-1, 9, 9, 768]               0\n",
      "          Linear-159           [-1, 9, 9, 3072]       2,362,368\n",
      "            GELU-160           [-1, 9, 9, 3072]               0\n",
      "         Dropout-161           [-1, 9, 9, 3072]               0\n",
      "          Linear-162            [-1, 9, 9, 768]       2,360,064\n",
      "         Dropout-163            [-1, 9, 9, 768]               0\n",
      "       LayerNorm-164            [-1, 9, 9, 768]           1,536\n",
      " StochasticDepth-165            [-1, 9, 9, 768]               0\n",
      "SwinTransformerBlockV2-166            [-1, 9, 9, 768]               0\n",
      "          Linear-167          [-1, 15, 15, 512]           1,536\n",
      "            ReLU-168          [-1, 15, 15, 512]               0\n",
      "          Linear-169           [-1, 15, 15, 24]          12,288\n",
      "ShiftedWindowAttentionV2-170            [-1, 9, 9, 768]               0\n",
      "       LayerNorm-171            [-1, 9, 9, 768]           1,536\n",
      " StochasticDepth-172            [-1, 9, 9, 768]               0\n",
      "          Linear-173           [-1, 9, 9, 3072]       2,362,368\n",
      "            GELU-174           [-1, 9, 9, 3072]               0\n",
      "         Dropout-175           [-1, 9, 9, 3072]               0\n",
      "          Linear-176            [-1, 9, 9, 768]       2,360,064\n",
      "         Dropout-177            [-1, 9, 9, 768]               0\n",
      "       LayerNorm-178            [-1, 9, 9, 768]           1,536\n",
      " StochasticDepth-179            [-1, 9, 9, 768]               0\n",
      "SwinTransformerBlockV2-180            [-1, 9, 9, 768]               0\n",
      "       LayerNorm-181            [-1, 9, 9, 768]           1,536\n",
      "         Permute-182            [-1, 768, 9, 9]               0\n",
      "AdaptiveAvgPool2d-183            [-1, 768, 1, 1]               0\n",
      "         Flatten-184                  [-1, 768]               0\n",
      "          Linear-185                   [-1, 28]          21,532\n",
      "================================================================\n",
      "Total params: 18,960,124\n",
      "Trainable params: 18,960,124\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.77\n",
      "Forward/backward pass size (MB): 348.50\n",
      "Params size (MB): 72.33\n",
      "Estimated Total Size (MB): 421.60\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(swinv2_model.to(\"cuda\"), (3,260,260))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegNet(\n",
       "  (stem): SimpleStemIN(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (trunk_output): Sequential(\n",
       "    (block1): AnyStage(\n",
       "      (block1-0): ResBottleneckBlock(\n",
       "        (proj): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 72, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (f): BottleneckTransform(\n",
       "          (a): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (b): Conv2dNormActivation(\n",
       "            (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=3, bias=False)\n",
       "            (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(72, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(8, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (c): Conv2dNormActivation(\n",
       "            (0): Conv2d(72, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "      (block1-1): ResBottleneckBlock(\n",
       "        (f): BottleneckTransform(\n",
       "          (a): Conv2dNormActivation(\n",
       "            (0): Conv2d(72, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (b): Conv2dNormActivation(\n",
       "            (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3, bias=False)\n",
       "            (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(72, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(18, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (c): Conv2dNormActivation(\n",
       "            (0): Conv2d(72, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (block2): AnyStage(\n",
       "      (block2-0): ResBottleneckBlock(\n",
       "        (proj): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 216, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (f): BottleneckTransform(\n",
       "          (a): Conv2dNormActivation(\n",
       "            (0): Conv2d(72, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (b): Conv2dNormActivation(\n",
       "            (0): Conv2d(216, 216, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=9, bias=False)\n",
       "            (1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(216, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(18, 216, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (c): Conv2dNormActivation(\n",
       "            (0): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "      (block2-1): ResBottleneckBlock(\n",
       "        (f): BottleneckTransform(\n",
       "          (a): Conv2dNormActivation(\n",
       "            (0): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (b): Conv2dNormActivation(\n",
       "            (0): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=9, bias=False)\n",
       "            (1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(216, 54, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(54, 216, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (c): Conv2dNormActivation(\n",
       "            (0): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "      (block2-2): ResBottleneckBlock(\n",
       "        (f): BottleneckTransform(\n",
       "          (a): Conv2dNormActivation(\n",
       "            (0): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (b): Conv2dNormActivation(\n",
       "            (0): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=9, bias=False)\n",
       "            (1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(216, 54, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(54, 216, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (c): Conv2dNormActivation(\n",
       "            (0): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "      (block2-3): ResBottleneckBlock(\n",
       "        (f): BottleneckTransform(\n",
       "          (a): Conv2dNormActivation(\n",
       "            (0): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (b): Conv2dNormActivation(\n",
       "            (0): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=9, bias=False)\n",
       "            (1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(216, 54, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(54, 216, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (c): Conv2dNormActivation(\n",
       "            (0): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "      (block2-4): ResBottleneckBlock(\n",
       "        (f): BottleneckTransform(\n",
       "          (a): Conv2dNormActivation(\n",
       "            (0): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (b): Conv2dNormActivation(\n",
       "            (0): Conv2d(216, 216, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=9, bias=False)\n",
       "            (1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(216, 54, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(54, 216, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (c): Conv2dNormActivation(\n",
       "            (0): Conv2d(216, 216, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (block3): AnyStage(\n",
       "      (block3-0): ResBottleneckBlock(\n",
       "        (proj): Conv2dNormActivation(\n",
       "          (0): Conv2d(216, 576, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (f): BottleneckTransform(\n",
       "          (a): Conv2dNormActivation(\n",
       "            (0): Conv2d(216, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (b): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(576, 54, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(54, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (c): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "      (block3-1): ResBottleneckBlock(\n",
       "        (f): BottleneckTransform(\n",
       "          (a): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (b): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (c): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "      (block3-2): ResBottleneckBlock(\n",
       "        (f): BottleneckTransform(\n",
       "          (a): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (b): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (c): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "      (block3-3): ResBottleneckBlock(\n",
       "        (f): BottleneckTransform(\n",
       "          (a): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (b): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (c): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "      (block3-4): ResBottleneckBlock(\n",
       "        (f): BottleneckTransform(\n",
       "          (a): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (b): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (c): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "      (block3-5): ResBottleneckBlock(\n",
       "        (f): BottleneckTransform(\n",
       "          (a): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (b): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (c): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "      (block3-6): ResBottleneckBlock(\n",
       "        (f): BottleneckTransform(\n",
       "          (a): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (b): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (c): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "      (block3-7): ResBottleneckBlock(\n",
       "        (f): BottleneckTransform(\n",
       "          (a): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (b): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (c): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "      (block3-8): ResBottleneckBlock(\n",
       "        (f): BottleneckTransform(\n",
       "          (a): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (b): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (c): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "      (block3-9): ResBottleneckBlock(\n",
       "        (f): BottleneckTransform(\n",
       "          (a): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (b): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (c): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "      (block3-10): ResBottleneckBlock(\n",
       "        (f): BottleneckTransform(\n",
       "          (a): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (b): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (c): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "      (block3-11): ResBottleneckBlock(\n",
       "        (f): BottleneckTransform(\n",
       "          (a): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (b): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (c): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "      (block3-12): ResBottleneckBlock(\n",
       "        (f): BottleneckTransform(\n",
       "          (a): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (b): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (c): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (block4): AnyStage(\n",
       "      (block4-0): ResBottleneckBlock(\n",
       "        (proj): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 1512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (f): BottleneckTransform(\n",
       "          (a): Conv2dNormActivation(\n",
       "            (0): Conv2d(576, 1512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (b): Conv2dNormActivation(\n",
       "            (0): Conv2d(1512, 1512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=63, bias=False)\n",
       "            (1): BatchNorm2d(1512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (se): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1512, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(144, 1512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (c): Conv2dNormActivation(\n",
       "            (0): Conv2d(1512, 1512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (activation): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=1512, out_features=28, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): FusedMBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "      )\n",
       "      (1): FusedMBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.005, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): FusedMBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.01, mode=row)\n",
       "      )\n",
       "      (1): FusedMBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.015000000000000003, mode=row)\n",
       "      )\n",
       "      (2): FusedMBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.02, mode=row)\n",
       "      )\n",
       "      (3): FusedMBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): FusedMBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.030000000000000006, mode=row)\n",
       "      )\n",
       "      (1): FusedMBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.035, mode=row)\n",
       "      )\n",
       "      (2): FusedMBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.04, mode=row)\n",
       "      )\n",
       "      (3): FusedMBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.045, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.05500000000000001, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.06000000000000001, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.065, mode=row)\n",
       "      )\n",
       "      (4): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07, mode=row)\n",
       "      )\n",
       "      (5): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "            (1): BatchNorm2d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.075, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "            (1): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.08, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.085, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.09, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.095, mode=row)\n",
       "      )\n",
       "      (4): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "      )\n",
       "      (5): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.10500000000000001, mode=row)\n",
       "      )\n",
       "      (6): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.11000000000000001, mode=row)\n",
       "      )\n",
       "      (7): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.11500000000000002, mode=row)\n",
       "      )\n",
       "      (8): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.12000000000000002, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.13, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.135, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.14, mode=row)\n",
       "      )\n",
       "      (4): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.14500000000000002, mode=row)\n",
       "      )\n",
       "      (5): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.15, mode=row)\n",
       "      )\n",
       "      (6): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.155, mode=row)\n",
       "      )\n",
       "      (7): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.16, mode=row)\n",
       "      )\n",
       "      (8): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.165, mode=row)\n",
       "      )\n",
       "      (9): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.17, mode=row)\n",
       "      )\n",
       "      (10): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.175, mode=row)\n",
       "      )\n",
       "      (11): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.18, mode=row)\n",
       "      )\n",
       "      (12): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.185, mode=row)\n",
       "      )\n",
       "      (13): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.19, mode=row)\n",
       "      )\n",
       "      (14): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "            (1): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1536, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(64, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.195, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (7): Conv2dNormActivation(\n",
       "      (0): Conv2d(256, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=1280, out_features=28, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SwinTransformer(\n",
       "  (features): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "      (1): Permute()\n",
       "      (2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "          (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=3, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=96, out_features=384, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "          (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=3, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.018181818181818184, mode=row)\n",
       "        (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=96, out_features=384, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): PatchMergingV2(\n",
       "      (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
       "      (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "          (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=6, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.03636363636363637, mode=row)\n",
       "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "          (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=6, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.05454545454545456, mode=row)\n",
       "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): PatchMergingV2(\n",
       "      (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
       "      (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07272727272727274, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.09090909090909091, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.10909090909090911, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1272727272727273, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.14545454545454548, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.16363636363636364, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): PatchMergingV2(\n",
       "      (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
       "      (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=24, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.18181818181818182, mode=row)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=24, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.2, mode=row)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (permute): Permute()\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (head): Linear(in_features=768, out_features=28, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swinv2_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
